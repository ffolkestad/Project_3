{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network with two hidden layers and ReLU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, classification_report\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the dataset\n",
    "covertype = fetch_ucirepo(id=31)\n",
    "X = covertype.data.features.to_numpy()\n",
    "y = covertype.data.targets.to_numpy()\n",
    "\n",
    "# One-hot representation of labels, lecture notes week 43\n",
    "y_onehot = to_categorical(y-1) #The first class starts at 0\n",
    "\n",
    "# Split into train and test data, 40% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.4, random_state=1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the model, lecture notes week 43\n",
    "def create_network(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd):\n",
    "  model = Sequential([\n",
    "      # Using relu activation function, and L2-regularization. \n",
    "      Input(shape=(X_train.shape[1],)),\n",
    "      Dense(n_neurons_layer1, activation=activation, kernel_regularizer=l2(lmbd)),\n",
    "      BatchNormalization(),\n",
    "      Dense(n_neurons_layer2, activation=activation, kernel_regularizer=l2(lmbd)),\n",
    "      BatchNormalization(),\n",
    "      Dense(n_categories, activation='softmax')\n",
    "  ])\n",
    "  # Defining the optimizer, loss and metrics.\n",
    "  model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=eta),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 128\n",
    "n_neurons_layer2 = 64\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001 #learning rate\n",
    "lmbd = 0.002 #l2 regularization\n",
    "activation = \"relu\"\n",
    "\n",
    "# Create network\n",
    "model_1 = create_network(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_1.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 1 (%)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_1.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 1:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 1:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 64\n",
    "n_neurons_layer2 = 32\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001\n",
    "lmbd = 0.001\n",
    "activation = \"relu\"\n",
    "\n",
    "# Create network\n",
    "model_2 = create_network(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_2.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 2 (%)\")\n",
    "plt.show()\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_2.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 2:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 2:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network with two hidden layers, and leaky-ReLU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the model, lecture notes week 43\n",
    "def create_network_leaky_relu(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd):\n",
    "  model = Sequential([\n",
    "      Input(shape=(X_train.shape[1],)),\n",
    "      Dense(n_neurons_layer1, kernel_regularizer=l2(lmbd)),\n",
    "      LeakyReLU(negative_slope=0.1),  # LeakyReLU\n",
    "      BatchNormalization(),\n",
    "      Dense(n_neurons_layer2, kernel_regularizer=l2(lmbd)),\n",
    "      LeakyReLU(negative_slope=0.1),  # LeakyReLU\n",
    "      BatchNormalization(),\n",
    "      Dense(n_categories, activation='softmax')\n",
    "  ])\n",
    "# Defining the optimizer, loss and metrics.\n",
    "  model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=eta),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 128\n",
    "n_neurons_layer2 = 64\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001\n",
    "lmbd = 0.001\n",
    "\n",
    "# Create network\n",
    "model_3 = create_network_leaky_relu(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_3.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_3.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 3 (%)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_3.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 3:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 3:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 64\n",
    "n_neurons_layer2 = 32\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001\n",
    "lmbd = 0.001\n",
    "\n",
    "# Create network\n",
    "model_4 = create_network_leaky_relu(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_4.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_4.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_4.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 4 (%)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_4.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 4:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 4:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network with two hidden layers, and ELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 128\n",
    "n_neurons_layer2 = 64\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001\n",
    "lmbd = 0.001\n",
    "activation = \"elu\"\n",
    "\n",
    "# Create network\n",
    "model_5 = create_network(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_5.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_5.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_5.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 5 (%)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_5.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 5:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 5:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "n_neurons_layer1 = 64\n",
    "n_neurons_layer2 = 32\n",
    "n_categories = y_train.shape[1]\n",
    "eta = 0.001\n",
    "lmbd = 0.001\n",
    "activation = \"elu\"\n",
    "\n",
    "# Create network\n",
    "model_6 = create_network(n_neurons_layer1, n_neurons_layer2, n_categories, eta, lmbd)\n",
    "\n",
    "# Train the model\n",
    "history = model_6.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),verbose=0)\n",
    "\n",
    "# Calculate test-accuracy and loss for the model\n",
    "test_loss, test_accuracy = model_6.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model_6.predict(X_test)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = y_test.argmax(axis=1)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "class_names = np.unique(y)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # To show the results in %. \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)  # Add 1 to shift labels to 1-based indexing\n",
    "disp.plot(cmap=\"viridis\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix for Model 6 (%)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model_6.predict(X_train)\n",
    "train_predicted_classes = train_predictions.argmax(axis=1)\n",
    "train_true_classes = y_train.argmax(axis=1)\n",
    "\n",
    "# Generate classification report for training set\n",
    "train_report = classification_report(train_true_classes, train_predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Training Classification Report for Model 6:\")\n",
    "print(train_report)\n",
    "\n",
    "# Generate classification report for test set\n",
    "test_report = classification_report(true_classes, predicted_classes, target_names=[f\"Class {i+1}\" for i in range(n_categories)])\n",
    "print(\"Test Classification Report for Model 6:\")\n",
    "print(test_report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
